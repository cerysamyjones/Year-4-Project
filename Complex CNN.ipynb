{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Complex Neural Network Problem\n",
    "\n",
    "<font size = 3>In order to test out using a more complex neural network, we needed a more complicated problem. This involved building a neural network that could classify AGN with jets into three groups dependent on the bending angle between the jets.\n",
    "\n",
    "Group 1: ang < 20 degrees (wide tail radio galaxies)\n",
    "\n",
    "<br>\n",
    "Group 2: 20 < ang < 45 degrees\n",
    "\n",
    "Group 3: ang > 45 degrees (bent tail radio galaxies)\n",
    "\n",
    "Garon et al published a paper in 2019 that measured the bending angle for our previous training set of jet sources, so we could simply use this angle information along with our previous training set for this problem. \n",
    "\n",
    "It should be noted that we first attemped to solve this problem using our simple neural network, and this achieved an accuracy of around 90%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from astropy.io import fits \n",
    "from astropy import stats\n",
    "from scipy.ndimage import rotate \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clipped_images(filepath,xpix,ypix,sigma):\n",
    "    '''\n",
    "    Put FITS data from desired folder into a 3D array\n",
    "    sigma = how many sigmas from the median background value to sigma clip the data to\n",
    "    \n",
    "    TODO: Need to check for .fits ending so works if other files in directory\n",
    "    '''\n",
    "    newpath = filepath.replace(os.sep, '/')\n",
    "    dirs = os.listdir(newpath)\n",
    "    n = len(dirs)\n",
    "    data = np.empty(shape=(n,xpix,ypix),dtype=np.float64)\n",
    "    for i in range(n):\n",
    "        fullpath = '{}/{}'.format(newpath,dirs[i])\n",
    "        d = fits.getdata(fullpath, ext=0)\n",
    "        d[np.isnan(d)] = 0\n",
    "        _,median,std = stats.sigma_clipped_stats(d, sigma=sigma)\n",
    "        d[d<median+sigma*std] = median+sigma*std\n",
    "        data[i,:,:] = d\n",
    "    return data\n",
    "\n",
    "def augment_data(data,size,xpix,ypix):\n",
    "    '''\n",
    "    Augment the data (3D array of images) by flipping and rotating the images.\n",
    "    Size = upper bound on the final number of images \n",
    "    (actual_size can be much less depending on size/data_size multiples)\n",
    "    \n",
    "    TODO: Make the actual size = size\n",
    "    '''\n",
    "    rotations = size//len(data) # rotations per image\n",
    "    angles = np.linspace(0, 360, rotations)\n",
    "    act_size = rotations*len(data)\n",
    "    training_set = np.empty((act_size, xpix, ypix))\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(angles)):\n",
    "            if j % 2 == 0: training_set[i*len(angles)+j,:,:] = rotate(np.fliplr(data[i,:,:]), angles[j], reshape=False)\n",
    "            else: training_set[i*len(angles)+j,:,:] = rotate(data[i,:,:], angles[j], reshape=False)\n",
    "    return training_set\n",
    "\n",
    "def train_test(data,percentage):\n",
    "    '''\n",
    "    Combines data sets in one 3D array, with a different label for each data set.\n",
    "    Then randomly shuffles the data and splits into training and test sets.\n",
    "    data = list 3D arrays containing desired data sets\n",
    "    per = fraction of data to be in training set\n",
    "    returns: train and test data (each a tupple containing the data and corresponding labels)\n",
    "    '''\n",
    "    d = np.concatenate(data,axis=0)\n",
    "    n_images = len(d)\n",
    "    labels = np.empty(n_images)\n",
    "    i = 0\n",
    "    for n in range(len(data)):\n",
    "        labels[i:i+len(data[n])] = n\n",
    "        i += len(data[n])\n",
    "    rand_ind = np.random.permutation(range(n_images))\n",
    "    d, labels = d[rand_ind], labels[rand_ind]\n",
    "    n_train = np.int(np.round(n_images*percentage))\n",
    "    train = (d[:n_train], labels[:n_train])\n",
    "    test = (d[n_train:], labels[n_train:])\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3> Before the training set can be used, we have to split up the data according to bending angle and create a label for each image that corresponds to the category it has been placed in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of x pixels and y pixels in each image (must be the same for all images)\n",
    "xpix, ypix = 83, 83\n",
    "\n",
    "# Directories with the FITS data\n",
    "agn_path = r'C:\\Users\\Cerys\\Documents\\Physics\\Y4 Project\\Data Preparation\\Radio Zoo Images'\n",
    "agn_data = get_clipped_images(agn_path,xpix,ypix,sigma=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = r'C:\\Users\\Cerys\\Documents\\Physics\\Y4 Project\\Data Preparation\\ra dec ang.txt'\n",
    "agn_ang = np.array(pd.read_csv(datapath, sep='\\s+', header=None, usecols=[2])) # bending angle of agn, from vizier catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define angle ranges for three different categories of AGN\n",
    "ang1 = 20\n",
    "ang2 = 45\n",
    "\n",
    "# Assign each image in agn_data a label depending on which angle range it is in\n",
    "labels = np.empty(len(agn_data))\n",
    "for i in range(len(agn_ang)):\n",
    "    if agn_ang[i] < ang1: labels[i] = 1\n",
    "    elif agn_ang[i] > ang2: labels[i] = 3\n",
    "    else: labels[i] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat1 = agn_data[labels==1]\n",
    "cat2 = agn_data[labels==2]\n",
    "cat3 = agn_data[labels==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment the data\n",
    "data = [] # empty list\n",
    "for cat in (cat1,cat2,cat3):\n",
    "    data.append(augment_data(cat,30000,xpix,ypix))\n",
    "\n",
    "# Get training and test data and labels\n",
    "train, test = train_test(data, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aniyan Paper Model\n",
    "\n",
    "<font size = 3> It was decided that the best approach to start this problem was to try and recreate the neural network seen in Aniyan's paper. The model below is as close a replica as possible to that in the paper and unfortunately the vast number of trainable parameters (58 million) made it too complicated to run on a regular machine. In order to test this network efficiently, we will need to use GPUs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 73, 73, 96)        11712     \n",
      "_________________________________________________________________\n",
      "layer_normalization_4 (Layer (None, 73, 73, 96)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 24, 24, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 20, 20, 256)       614656    \n",
      "_________________________________________________________________\n",
      "layer_normalization_5 (Layer (None, 20, 20, 256)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 10, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 384)         885120    \n",
      "_________________________________________________________________\n",
      "layer_normalization_6 (Layer (None, 8, 8, 384)         768       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 6, 6, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "layer_normalization_7 (Layer (None, 6, 6, 384)         768       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 4, 256)         884992    \n",
      "_________________________________________________________________\n",
      "layer_normalization_8 (Layer (None, 4, 4, 256)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4096)              4198400   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 8192)              33562624  \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 24579     \n",
      "=================================================================\n",
      "Total params: 58,293,635\n",
      "Trainable params: 58,293,635\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Aniyan Model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(96, (11, 11), activation='relu', input_shape=(83, 83, 1)),\n",
    "    tf.keras.layers.LayerNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D((3, 3)),\n",
    "    tf.keras.layers.Conv2D(256, (5, 5), activation='relu'),\n",
    "    tf.keras.layers.LayerNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(384, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.LayerNormalization(),\n",
    "    tf.keras.layers.Conv2D(384, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.LayerNormalization(),\n",
    "    tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.LayerNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(4096, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(4096, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(4096*2, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(3, activation='softmax') ])\n",
    "    \n",
    "model.summary()\n",
    "\n",
    "# Compile the network\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = tf.reshape(train[0], [-1, 83, 83, 1])\n",
    "labels = train[1]\n",
    "\n",
    "model.fit(training, labels,epochs=5,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal Neural Network\n",
    "\n",
    "<font size = 3> Due to the large runtime of the Aniyan model, it was better to start with something simpler (less trainable parameters) and see if that would work first. \n",
    "\n",
    "The options for refining the network included:\n",
    "\n",
    "- Changing the number of convolutional, pooling, and densely connected layers.\n",
    "- Changing the number of nodes at each layer.\n",
    "- Chaniging the kernel size of the convolutional layers.\n",
    "- Changing the activation function.\n",
    "\n",
    "After trialling several attempts changing all of these parameters, the network below was decided upon to be the best. It only has 1 million trainable parameters resulting in a run time of around 5 hours, but the accuracy is around 97% which is much better than the simple neural net was for this problem (around 90%). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment the data\n",
    "# Note - augmenting the data to around 40000 images produced the best possible results without overly increasing runtime.\n",
    "# Would be worth checking if augmenting the data even further increases the accuracy, but not the priorty for this test.\n",
    "for cat in (cat1,cat2,cat3):\n",
    "    data.append(augment_data(cat,40000,xpix,ypix))\n",
    "\n",
    "# Get training and test data and labels\n",
    "train, test = train_test(data, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 81, 81, 32)        320       \n",
      "_________________________________________________________________\n",
      "layer_normalization (LayerNo (None, 81, 81, 32)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 27, 27, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 25, 25, 32)        9248      \n",
      "_________________________________________________________________\n",
      "layer_normalization_1 (Layer (None, 25, 25, 32)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               1179904   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 1,190,371\n",
      "Trainable params: 1,190,371\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(83, 83, 1)))\n",
    "model.add(tf.keras.layers.LayerNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D((3, 3)))\n",
    "model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.LayerNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.15)) \n",
    "model.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Compile the network\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 94428 samples\n",
      "Epoch 1/20\n",
      "94428/94428 [==============================] - 731s 8ms/sample - loss: 0.0879 - accuracy: 0.9661\n",
      "Epoch 2/20\n",
      "94428/94428 [==============================] - 736s 8ms/sample - loss: 0.0927 - accuracy: 0.9658\n",
      "Epoch 3/20\n",
      "94428/94428 [==============================] - 749s 8ms/sample - loss: 0.0767 - accuracy: 0.9701\n",
      "Epoch 4/20\n",
      "94428/94428 [==============================] - 761s 8ms/sample - loss: 0.0780 - accuracy: 0.9700\n",
      "Epoch 5/20\n",
      "94428/94428 [==============================] - 1038s 11ms/sample - loss: 0.0757 - accuracy: 0.9707\n",
      "Epoch 6/20\n",
      "94428/94428 [==============================] - 1185s 13ms/sample - loss: 0.0809 - accuracy: 0.9694\n",
      "Epoch 7/20\n",
      "94428/94428 [==============================] - 1209s 13ms/sample - loss: 0.0661 - accuracy: 0.9739\n",
      "Epoch 8/20\n",
      "94428/94428 [==============================] - 1207s 13ms/sample - loss: 0.0700 - accuracy: 0.9731\n",
      "Epoch 9/20\n",
      "94428/94428 [==============================] - 1023s 11ms/sample - loss: 0.0675 - accuracy: 0.9741\n",
      "Epoch 10/20\n",
      "94428/94428 [==============================] - 762s 8ms/sample - loss: 0.0800 - accuracy: 0.9714\n",
      "Epoch 11/20\n",
      "94428/94428 [==============================] - 767s 8ms/sample - loss: 0.0611 - accuracy: 0.9769\n",
      "Epoch 12/20\n",
      "94428/94428 [==============================] - 768s 8ms/sample - loss: 0.0700 - accuracy: 0.9739\n",
      "Epoch 13/20\n",
      "94428/94428 [==============================] - 771s 8ms/sample - loss: 0.0609 - accuracy: 0.9770\n",
      "Epoch 14/20\n",
      "94428/94428 [==============================] - 771s 8ms/sample - loss: 0.0585 - accuracy: 0.9774\n",
      "Epoch 15/20\n",
      "94428/94428 [==============================] - 771s 8ms/sample - loss: 0.0576 - accuracy: 0.9780\n",
      "Epoch 16/20\n",
      "94428/94428 [==============================] - 781s 8ms/sample - loss: 0.0586 - accuracy: 0.9779\n",
      "Epoch 17/20\n",
      "94428/94428 [==============================] - 781s 8ms/sample - loss: 0.0574 - accuracy: 0.9783\n",
      "Epoch 18/20\n",
      "94428/94428 [==============================] - 781s 8ms/sample - loss: 0.0498 - accuracy: 0.9816\n",
      "Epoch 19/20\n",
      "94428/94428 [==============================] - 780s 8ms/sample - loss: 0.0528 - accuracy: 0.9798\n",
      "Epoch 20/20\n",
      "94428/94428 [==============================] - 779s 8ms/sample - loss: 0.0734 - accuracy: 0.9754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25844a1f6d8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training = tf.reshape(train[0], [-1, 83, 83, 1])\n",
    "labels = train[1]\n",
    "\n",
    "model.fit(training, labels,epochs=20,verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.reshape(train[0], [-1, 83, 83, 1])\n",
    "test_labels = train[1]\n",
    "test_loss, test_acc = model.evaluate(test,test_labels, verbose=1)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
