{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple neural network\n",
    "<font size = 3> Simple neural network tasked with identifying AGN with jets from point sources with close to 100% accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from astropy.io import fits \n",
    "from astropy import stats\n",
    "from scipy.ndimage import rotate\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These functions have since been updated and streamlined and are included in the building training set file. \n",
    "\n",
    "def get_clipped_images(filepath,xpix,ypix,sigma):\n",
    "    '''\n",
    "    Put FITS data from desired folder into a 3D array\n",
    "    sigma = how many sigmas from the median background value to sigma clip the data to\n",
    "    '''\n",
    "    newpath = filepath.replace(os.sep, '/')\n",
    "    dirs = os.listdir(newpath)\n",
    "    n = len(dirs)\n",
    "    data = np.empty(shape=(n,xpix,ypix),dtype=np.float64)\n",
    "    for i in range(n):\n",
    "        fullpath = '{}/{}'.format(newpath,dirs[i])\n",
    "        d = fits.getdata(fullpath, ext=0)\n",
    "        d[np.isnan(d)] = 0\n",
    "        _,median,std = stats.sigma_clipped_stats(d, sigma=sigma)\n",
    "        d[d<median+sigma*std] = median+sigma*std\n",
    "        data[i,:,:] = d\n",
    "    return data\n",
    "\n",
    "def augment_data(data,size,xpix,ypix):\n",
    "    '''\n",
    "    Augment the data (3D array of images) by flipping and rotating the images.\n",
    "    Size = upper bound on the final number of images \n",
    "    (actual_size can be much less depending on size/data_size multiples)\n",
    "    '''\n",
    "    rotations = size//len(data) # rotations per image\n",
    "    angles = np.linspace(0, 360, rotations)\n",
    "    act_size = rotations*len(data)\n",
    "    training_set = np.empty((act_size, xpix, ypix))\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(angles)):\n",
    "            if j % 2 == 0: training_set[i*len(angles)+j,:,:] = rotate(np.fliplr(data[i,:,:]), angles[j], reshape=False)\n",
    "            else: training_set[i*len(angles)+j,:,:] = rotate(data[i,:,:], angles[j], reshape=False)\n",
    "    return training_set\n",
    "\n",
    "def train_test(data,percentage):\n",
    "    '''\n",
    "    Combines data sets in one 3D array, with a different label for each data set.\n",
    "    Then randomly shuffles the data and splits into training and test sets.\n",
    "    data = list 3D arrays containing desired data sets\n",
    "    per = fraction of data to be in training set\n",
    "    returns: train and test data (each a tupple containing the data and corresponding labels)\n",
    "    '''\n",
    "    d = np.concatenate(data,axis=0)\n",
    "    n_images = len(d)\n",
    "    labels = np.empty(n_images)\n",
    "    i = 0\n",
    "    for n in range(len(data)):\n",
    "        labels[i:i+len(data[n])] = n\n",
    "        i = len(data[n])\n",
    "    rand_ind = np.random.permutation(range(n_images))\n",
    "    d, labels = d[rand_ind], labels[rand_ind]\n",
    "    n_train = np.int(np.round(n_images*percentage))\n",
    "    train = (d[:n_train], labels[:n_train])\n",
    "    test = (d[n_train:], labels[n_train:])\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of x pixels and y pixels in each image (must be the same for all images)\n",
    "xpix, ypix = 83, 83\n",
    "\n",
    "# Directories with the FITS data\n",
    "agn_path = r'C:\\Users\\Cerys\\Documents\\Physics\\Y4 Project\\Data Preparation\\Radio Zoo Images'\n",
    "ps_path = r'C:\\Users\\Cerys\\Documents\\Physics\\Y4 Project\\Data Preparation\\Stars'\n",
    "\n",
    "# Get FITs images and augment data sets\n",
    "agn_data = get_clipped_images(agn_path,xpix,ypix,sigma=3)\n",
    "ps_data = get_clipped_images(ps_path,xpix,ypix,sigma=1)\n",
    "agn_augment = augment_data(agn_data,10000,xpix,ypix)\n",
    "ps_augment = augment_data(ps_data,10000,xpix,ypix)\n",
    "\n",
    "data = (agn_augment, ps_augment) # list of all data sets to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test(data,0.2) # training and test data, each in a tuple with data label array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(xpix, ypix)),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(0.3),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "    \n",
    "# Compile the network\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3482 samples\n",
      "Epoch 1/10\n",
      "3482/3482 [==============================] - 3s 893us/sample - loss: 0.7643 - accuracy: 0.9024\n",
      "Epoch 2/10\n",
      "3482/3482 [==============================] - 2s 679us/sample - loss: 0.0353 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "3482/3482 [==============================] - 2s 712us/sample - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "3482/3482 [==============================] - 2s 667us/sample - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "3482/3482 [==============================] - 2s 650us/sample - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "3482/3482 [==============================] - 2s 662us/sample - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "3482/3482 [==============================] - 2s 626us/sample - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "3482/3482 [==============================] - 2s 618us/sample - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "3482/3482 [==============================] - 2s 634us/sample - loss: 9.8631e-04 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "3482/3482 [==============================] - 2s 608us/sample - loss: 8.2200e-04 - accuracy: 1.0000\n",
      "13930/1 - 2s - loss: 0.0017 - accuracy: 0.9997\n",
      "\n",
      "Test accuracy: 0.9997128\n"
     ]
    }
   ],
   "source": [
    "# Perform fit\n",
    "model.fit(*train, epochs=10)\n",
    "test_loss, test_acc = model.evaluate(*test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above shows can achieve 100% accuracy between point sources and AGN with jets even with a simple neural net."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
